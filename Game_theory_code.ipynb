{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Game theory code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYkjisW7gLAn/A8QecUjAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omarelfarouk90/operation-research-codes/blob/main/Game_theory_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credits to Enginer Brandon smith "
      ],
      "metadata": {
        "id": "4YGJL7x6mlsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets start with the prisoner's dilema , we have the following output \n",
        "\n"
      ],
      "metadata": {
        "id": "KNmKqwFTmp-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tG60aQixyvE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install quantecon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo93bqkHn7PI",
        "outputId": "c2eee882-f66c-4012-9840-e36301617492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting quantecon\n",
            "  Downloading quantecon-0.5.2-py3-none-any.whl (269 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 204 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 215 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 225 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 269 kB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from quantecon) (2.23.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from quantecon) (1.7.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from quantecon) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from quantecon) (1.21.5)\n",
            "Requirement already satisfied: numba>=0.38 in /usr/local/lib/python3.7/dist-packages (from quantecon) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.38->quantecon) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.38->quantecon) (57.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->quantecon) (1.24.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->quantecon) (1.2.1)\n",
            "Installing collected packages: quantecon\n",
            "Successfully installed quantecon-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import quantecon as qe\n",
        "# create a list containing both players payoffs\n",
        "pt = [[(0.45,0.25), (0.60,0.2),(0.6,0.15)],[(0.40,0.30), (0.45,0.25),(0.5,0.15)],[(0.25,0.45), (0.35,0.30),(0.40,0.20)]]\n",
        "g1 = qe.game_theory.NormalFormGame(pt)\n",
        "print(g1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8W6N8vaIFwq",
        "outputId": "fc049ad8-8e40-430e-cc5c-b7b9aa2c8a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-player NormalFormGame with payoff profile array:\n",
            "[[[0.45, 0.25],  [0.6 , 0.2 ],  [0.6 , 0.15]],\n",
            " [[0.4 , 0.3 ],  [0.45, 0.25],  [0.5 , 0.15]],\n",
            " [[0.25, 0.45],  [0.35, 0.3 ],  [0.4 , 0.2 ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g1.players[0].payoff_array "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeQrwrHRI0yq",
        "outputId": "6fce9ce5-9497-4989-d6cc-d3c81a3c79a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45, 0.6 , 0.6 ],\n",
              "       [0.4 , 0.45, 0.5 ],\n",
              "       [0.25, 0.35, 0.4 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_best_response(g, init_actions=None, tie_breaking='smallest',\n",
        "                             verbose=True):\n",
        "    \"\"\"\n",
        "    Find a pure Nash equilibrium of a normal form game by sequential best\n",
        "    response.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    g : NormalFormGame\n",
        "\n",
        "    init_actions : array_like(int), optional(default=[0, ..., 0])\n",
        "        The initial action profile.\n",
        "\n",
        "    tie_breaking : {'smallest', 'random'}, optional(default='smallest')\n",
        "\n",
        "    verbose: bool, optional(default=True)\n",
        "        If True, print the intermediate process.\n",
        "\n",
        "    \"\"\"\n",
        "    N = g.N  # Number of players\n",
        "    a = np.empty(N, dtype=int)  # Action profile\n",
        "    if init_actions is None:\n",
        "        init_actions = [0] * N\n",
        "    a[:] = init_actions\n",
        "\n",
        "    if verbose:\n",
        "        print('init_actions: {0}'.format(a))\n",
        "\n",
        "    new_a = np.empty(N, dtype=int)\n",
        "    max_iter = np.prod(g.nums_actions)\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        new_a[:] = a\n",
        "        for i, player in enumerate(g.players):\n",
        "            if N == 2:\n",
        "                a_except_i = new_a[1-i]\n",
        "            else:\n",
        "                a_except_i = new_a[np.arange(i+1, i+N) % N]\n",
        "            new_a[i] = player.best_response(a_except_i,\n",
        "                                            tie_breaking=tie_breaking)\n",
        "            if verbose:\n",
        "                print('player {0}: {1}'.format(i, new_a))\n",
        "        if np.array_equal(new_a, a):\n",
        "            return a\n",
        "        else:\n",
        "            a[:] = new_a\n",
        "\n",
        "    print('No pure Nash equilibrium found')\n",
        "    return None"
      ],
      "metadata": {
        "id": "JscQH6auI3FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import quantecon.game_theory as gt"
      ],
      "metadata": {
        "id": "xkZxNJMqJCd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_star = sequential_best_response(g1)  # By default, start with (0, 0, 0)\n",
        "print('Nash equilibrium indices: {0}'.format(a_star))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er9DAVBfJHf5",
        "outputId": "154e5dc9-e18a-4aca-cd0f-09004ce90b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init_actions: [0 0]\n",
            "player 0: [0 0]\n",
            "player 1: [0 0]\n",
            "Nash equilibrium indices: [0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import quantecon as qe\n",
        "# create a list containing both players payoffs\n",
        "pt = [[(50,10), (80,25),(80,30)],[(65,20), (75,35),(85,30)],[(50,50), (70,45),(80,40)]]\n",
        "g2 = qe.game_theory.NormalFormGame(pt)\n",
        "print(g2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqzRHmyn5lI",
        "outputId": "58949359-f181-4007-bd39-cd3abc4d4715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-player NormalFormGame with payoff profile array:\n",
            "[[[50, 10],  [80, 25],  [80, 30]],\n",
            " [[65, 20],  [75, 35],  [85, 30]],\n",
            " [[50, 50],  [70, 45],  [80, 40]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g2.players[0].payoff_array "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c80Biev5u4b",
        "outputId": "2572970c-104f-4e45-a88a-a75245076fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[50, 80, 80],\n",
              "       [65, 75, 85],\n",
              "       [50, 70, 80]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Nash Equilibrium"
      ],
      "metadata": {
        "id": "2K9qt9_o6QDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_best_response(g, init_actions=None, tie_breaking='smallest',\n",
        "                             verbose=True):\n",
        "    \"\"\"\n",
        "    Find a pure Nash equilibrium of a normal form game by sequential best\n",
        "    response.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    g : NormalFormGame\n",
        "\n",
        "    init_actions : array_like(int), optional(default=[0, ..., 0])\n",
        "        The initial action profile.\n",
        "\n",
        "    tie_breaking : {'smallest', 'random'}, optional(default='smallest')\n",
        "\n",
        "    verbose: bool, optional(default=True)\n",
        "        If True, print the intermediate process.\n",
        "\n",
        "    \"\"\"\n",
        "    N = g.N  # Number of players\n",
        "    a = np.empty(N, dtype=int)  # Action profile\n",
        "    if init_actions is None:\n",
        "        init_actions = [0] * N\n",
        "    a[:] = init_actions\n",
        "\n",
        "    if verbose:\n",
        "        print('init_actions: {0}'.format(a))\n",
        "\n",
        "    new_a = np.empty(N, dtype=int)\n",
        "    max_iter = np.prod(g.nums_actions)\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        new_a[:] = a\n",
        "        for i, player in enumerate(g.players):\n",
        "            if N == 2:\n",
        "                a_except_i = new_a[1-i]\n",
        "            else:\n",
        "                a_except_i = new_a[np.arange(i+1, i+N) % N]\n",
        "            new_a[i] = player.best_response(a_except_i,\n",
        "                                            tie_breaking=tie_breaking)\n",
        "            if verbose:\n",
        "                print('player {0}: {1}'.format(i, new_a))\n",
        "        if np.array_equal(new_a, a):\n",
        "            return a\n",
        "        else:\n",
        "            a[:] = new_a\n",
        "\n",
        "    print('No pure Nash equilibrium found')\n",
        "    return None"
      ],
      "metadata": {
        "id": "fIEv6iea7XVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import quantecon.game_theory as gt"
      ],
      "metadata": {
        "id": "gNxfsQ0h8laB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tN-2pxhwaEv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a_star = sequential_best_response(g2)  # By default, start with (0, 0, 0)\n",
        "print('Nash equilibrium indices: {0}'.format(a_star))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl5tNcV87YtH",
        "outputId": "bf949060-ba0f-474b-a42b-33b2dfad27ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init_actions: [0 0]\n",
            "player 0: [1 0]\n",
            "player 1: [1 1]\n",
            "player 0: [0 1]\n",
            "player 1: [0 2]\n",
            "player 0: [1 2]\n",
            "player 1: [1 1]\n",
            "player 0: [0 1]\n",
            "player 1: [0 2]\n",
            "player 0: [1 2]\n",
            "player 1: [1 1]\n",
            "player 0: [0 1]\n",
            "player 1: [0 2]\n",
            "player 0: [1 2]\n",
            "player 1: [1 1]\n",
            "player 0: [0 1]\n",
            "player 1: [0 2]\n",
            "player 0: [1 2]\n",
            "player 1: [1 1]\n",
            "No pure Nash equilibrium found\n",
            "Nash equilibrium indices: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt.support_enumeration(g2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdMtmYWI7-2Y",
        "outputId": "4ea1e0b8-bba3-47a0-e7cb-d180508cd136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([0.5, 0.5, 0. ]), array([0. , 0.5, 0.5]))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 part A\n"
      ],
      "metadata": {
        "id": "ZO3X0HdEXrnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import quantecon as qe\n",
        "# create a list containing both players payoffs\n",
        "pt = [[(-200,0),(-200,0),(-200,0),(-200,0),(-200,0),(-200,0),(-200,0)],\n",
        "      [(0,-100),(-150,0),(-150,0),(-150,0),(-150,0),(-150,0),(-150,0)],\n",
        "      [(0,-100),(0,-50),(-100,0),(-100,0),(-100,0),(-100,0),(-100,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(-50,0),(-50,0),(-50,0),(-50,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(0,50),(0,0),(0,0),(0,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(0,50),(0,100),(50,0),(50,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(0,50),(0,100),(0,150),(100,0)]]\n",
        "g3 = qe.game_theory.NormalFormGame(pt)\n",
        "print(g3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lBbfq2XXub2",
        "outputId": "8093d14f-dbd3-4fa2-db21-d2cb96cbb73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-player NormalFormGame with payoff profile array:\n",
            "[[[-200,    0],  [-200,    0],  [-200,    0],  [-200,    0],  [-200,    0],  [-200,    0],  [-200,    0]],\n",
            " [[   0, -100],  [-150,    0],  [-150,    0],  [-150,    0],  [-150,    0],  [-150,    0],  [-150,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [-100,    0],  [-100,    0],  [-100,    0],  [-100,    0],  [-100,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [ -50,    0],  [ -50,    0],  [ -50,    0],  [ -50,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [   0,   50],  [   0,    0],  [   0,    0],  [   0,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [   0,   50],  [   0,  100],  [  50,    0],  [  50,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [   0,   50],  [   0,  100],  [   0,  150],  [ 100,    0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g3.players[0].payoff_array "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzZYbofjZ1RH",
        "outputId": "4777bd25-1373-4a66-fd82-e93a74fe90fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-200, -200, -200, -200, -200, -200, -200],\n",
              "       [   0, -150, -150, -150, -150, -150, -150],\n",
              "       [   0,    0, -100, -100, -100, -100, -100],\n",
              "       [   0,    0,    0,  -50,  -50,  -50,  -50],\n",
              "       [   0,    0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,   50,   50],\n",
              "       [   0,    0,    0,    0,    0,    0,  100]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_best_response(g, init_actions=None, tie_breaking='smallest',\n",
        "                             verbose=True):\n",
        "    \"\"\"\n",
        "    Find a pure Nash equilibrium of a normal form game by sequential best\n",
        "    response.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    g : NormalFormGame\n",
        "\n",
        "    init_actions : array_like(int), optional(default=[0, ..., 0])\n",
        "        The initial action profile.\n",
        "\n",
        "    tie_breaking : {'smallest', 'random'}, optional(default='smallest')\n",
        "\n",
        "    verbose: bool, optional(default=True)\n",
        "        If True, print the intermediate process.\n",
        "\n",
        "    \"\"\"\n",
        "    N = g.N  # Number of players\n",
        "    a = np.empty(N, dtype=int)  # Action profile\n",
        "    if init_actions is None:\n",
        "        init_actions = [0] * N\n",
        "    a[:] = init_actions\n",
        "\n",
        "    if verbose:\n",
        "        print('init_actions: {0}'.format(a))\n",
        "\n",
        "    new_a = np.empty(N, dtype=int)\n",
        "    max_iter = np.prod(g.nums_actions)\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        new_a[:] = a\n",
        "        for i, player in enumerate(g.players):\n",
        "            if N == 2:\n",
        "                a_except_i = new_a[1-i]\n",
        "            else:\n",
        "                a_except_i = new_a[np.arange(i+1, i+N) % N]\n",
        "            new_a[i] = player.best_response(a_except_i,\n",
        "                                            tie_breaking=tie_breaking)\n",
        "            if verbose:\n",
        "                print('player {0}: {1}'.format(i, new_a))\n",
        "        if np.array_equal(new_a, a):\n",
        "            return a\n",
        "        else:\n",
        "            a[:] = new_a\n",
        "\n",
        "    print('No pure Nash equilibrium found')\n",
        "    return None"
      ],
      "metadata": {
        "id": "YlJEC-g_Z-UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import quantecon.game_theory as gt"
      ],
      "metadata": {
        "id": "EIDTNwGhaHTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_star = sequential_best_response(g3)  # By default, start with (0, 0, 0)\n",
        "print('Nash equilibrium indices: {0}'.format(a_star))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ORvzGTaM0d",
        "outputId": "90b4b65d-a456-4156-8034-a31bf93e006b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init_actions: [0 0]\n",
            "player 0: [1 0]\n",
            "player 1: [1 1]\n",
            "player 0: [2 1]\n",
            "player 1: [2 2]\n",
            "player 0: [3 2]\n",
            "player 1: [3 2]\n",
            "player 0: [3 2]\n",
            "player 1: [3 2]\n",
            "Nash equilibrium indices: [3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt.support_enumeration(g3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vky-RNMmaREO",
        "outputId": "e1e59b7e-b597-43d9-a1ad-b24f4a65cf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0.])),\n",
              " (array([0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0.])),\n",
              " (array([0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 1., 0., 0.]))]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 part 2"
      ],
      "metadata": {
        "id": "f4DYHc9mbey1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import quantecon as qe\n",
        "# create a list containing both players payoffs\n",
        "pt = [[(-100,-50),(-200,0),(-200,0),(-200,0),(-200,0),(-200,0),(-200,0)],\n",
        "      [(0,-100),(-75,-25),(-150,0),(-150,0),(-150,0),(-150,0),(-150,0)],\n",
        "      [(0,-100),(0,-50),(-50,0),(-100,0),(-100,0),(-100,0),(-100,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(-25,25),(-50,0),(-50,0),(-50,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(0,50),(0,50),(0,0),(0,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(0,50),(0,100),(25,75),(50,0)],\n",
        "      [(0,-100),(0,-50),(0,0),(0,50),(0,100),(0,150),(50,100)]]\n",
        "g4 = qe.game_theory.NormalFormGame(pt)\n",
        "print(g4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76eAVI9xbbR-",
        "outputId": "643f0928-b53a-4948-fd73-616d14df8bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-player NormalFormGame with payoff profile array:\n",
            "[[[-100,  -50],  [-200,    0],  [-200,    0],  [-200,    0],  [-200,    0],  [-200,    0],  [-200,    0]],\n",
            " [[   0, -100],  [ -75,  -25],  [-150,    0],  [-150,    0],  [-150,    0],  [-150,    0],  [-150,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [ -50,    0],  [-100,    0],  [-100,    0],  [-100,    0],  [-100,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [ -25,   25],  [ -50,    0],  [ -50,    0],  [ -50,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [   0,   50],  [   0,   50],  [   0,    0],  [   0,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [   0,   50],  [   0,  100],  [  25,   75],  [  50,    0]],\n",
            " [[   0, -100],  [   0,  -50],  [   0,    0],  [   0,   50],  [   0,  100],  [   0,  150],  [  50,  100]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequential_best_response(g, init_actions=None, tie_breaking='smallest',\n",
        "                             verbose=True):\n",
        "    \"\"\"\n",
        "    Find a pure Nash equilibrium of a normal form game by sequential best\n",
        "    response.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    g : NormalFormGame\n",
        "\n",
        "    init_actions : array_like(int), optional(default=[0, ..., 0])\n",
        "        The initial action profile.\n",
        "\n",
        "    tie_breaking : {'smallest', 'random'}, optional(default='smallest')\n",
        "\n",
        "    verbose: bool, optional(default=True)\n",
        "        If True, print the intermediate process.\n",
        "\n",
        "    \"\"\"\n",
        "    N = g.N  # Number of players\n",
        "    a = np.empty(N, dtype=int)  # Action profile\n",
        "    if init_actions is None:\n",
        "        init_actions = [0] * N\n",
        "    a[:] = init_actions\n",
        "\n",
        "    if verbose:\n",
        "        print('init_actions: {0}'.format(a))\n",
        "\n",
        "    new_a = np.empty(N, dtype=int)\n",
        "    max_iter = np.prod(g.nums_actions)\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        new_a[:] = a\n",
        "        for i, player in enumerate(g.players):\n",
        "            if N == 2:\n",
        "                a_except_i = new_a[1-i]\n",
        "            else:\n",
        "                a_except_i = new_a[np.arange(i+1, i+N) % N]\n",
        "            new_a[i] = player.best_response(a_except_i,\n",
        "                                            tie_breaking=tie_breaking)\n",
        "            if verbose:\n",
        "                print('player {0}: {1}'.format(i, new_a))\n",
        "        if np.array_equal(new_a, a):\n",
        "            return a\n",
        "        else:\n",
        "            a[:] = new_a\n",
        "\n",
        "    print('No pure Nash equilibrium found')\n",
        "    return None"
      ],
      "metadata": {
        "id": "_T_5DJ_bcMnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import quantecon.game_theory as gt"
      ],
      "metadata": {
        "id": "t0QH02sYcQpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_star = sequential_best_response(g4)  # By default, start with (0, 0, 0)\n",
        "print('Nash equilibrium indices: {0}'.format(a_star))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKF2hHrucX2A",
        "outputId": "3e9cafba-124b-4fc9-d5b7-6914e94589d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init_actions: [0 0]\n",
            "player 0: [1 0]\n",
            "player 1: [1 2]\n",
            "player 0: [3 2]\n",
            "player 1: [3 3]\n",
            "player 0: [4 3]\n",
            "player 1: [4 3]\n",
            "player 0: [4 3]\n",
            "player 1: [4 3]\n",
            "Nash equilibrium indices: [4 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "سgt.support_enumeration(g4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnlti58pcuZX",
        "outputId": "1b90480f-ec22-45be-a460-3ce00673f124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0.])),\n",
              " (array([0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0.])),\n",
              " (array([0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 1., 0., 0.]))]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}